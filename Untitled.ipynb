{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b13656-43e7-4566-b0de-e33218b00121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Load and merge the datasets keeping all information available for the dates in which there is a measurement in “fx.csv”. [1 point]\n",
    "import pandas as pd\n",
    "\n",
    "fx=pd.read_csv(\"fx.csv\")\n",
    "speeches=pd.read_csv(\"speeches.csv\")\n",
    "\n",
    "speeches.rename(columns={\"when_speech\": \"Date\"}, inplace=True)  # Update with correct column name\n",
    "\n",
    "merged_df = fx.merge(speeches, on=\"Date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d0999a-e57f-4b53-ac35-1e8827e5a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = merged_df[\"USD\"].quantile(0.25)\n",
    "Q3 = merged_df[\"USD\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Remove values outside 1.5*IQR range\n",
    "merged_df = merged_df[(merged_df[\"USD\"] >= (Q1 - 1.5 * IQR)) & \n",
    "                       (merged_df[\"USD\"] <= (Q3 + 1.5 * IQR))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6cfdaf1-cf88-40cc-b1a3-1e4b33d20539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/14hxgrm51svd16v3p0d6pz5h0000gn/T/ipykernel_6736/2591464704.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"USD\"] = merged_df[\"USD\"].fillna(method=\"ffill\")  # Forward-fill missing values\n"
     ]
    }
   ],
   "source": [
    "merged_df[\"USD\"] = merged_df[\"USD\"].fillna(method=\"ffill\")  # Forward-fill missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e736ba7-ba9f-4033-a628-edb4e6ff142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"return\"] = merged_df[\"USD\"].pct_change() * 100  # Convert to percent\n",
    "merged_df[\"good_news\"] = (merged_df[\"return\"] > 0.5).astype(int)\n",
    "merged_df[\"bad_news\"] = (merged_df[\"return\"] < -0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dff8ffe5-daed-4135-b027-1bd2165a9f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=[\"what_title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7b561ad-5c47-4f9c-a665-e0ab7e8f594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Tokenize and clean function\n",
    "def extract_top_words(df, label_column):\n",
    "    all_words = \" \".join(df[df[label_column] == 1][\"what_title\"]).lower().split()\n",
    "    filtered_words = [word for word in all_words if word not in stop_words and word.isalpha()]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return pd.DataFrame(word_counts.most_common(20), columns=[\"word\", \"count\"])\n",
    "\n",
    "# Get top words for good and bad news\n",
    "good_indicators = extract_top_words(merged_df, \"good_news\")\n",
    "bad_indicators = extract_top_words(merged_df, \"bad_news\")\n",
    "\n",
    "# Save to CSV\n",
    "good_indicators.to_csv(\"good_indicators.csv\", index=False)\n",
    "bad_indicators.to_csv(\"bad_indicators.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19444fa5-164f-42b7-a86b-8d3c313f3b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'USD', 'JPY', 'BGN', 'CYP', 'CZK', 'DKK', 'EEK', 'GBP', 'HUF',\n",
      "       'LTL', 'LVL', 'MTL', 'PLN', 'ROL', 'RON', 'SEK', 'SIT', 'SKK', 'CHF',\n",
      "       'ISK', 'NOK', 'HRK', 'RUB', 'TRL', 'TRY', 'AUD', 'BRL', 'CAD', 'CNY',\n",
      "       'HKD', 'IDR', 'ILS', 'INR', 'KRW', 'MXN', 'MYR', 'NZD', 'PHP', 'SGD',\n",
      "       'THB', 'ZAR', 'Unnamed: 42'],\n",
      "      dtype='object')\n",
      "Index(['speech_id', 'when_speech', 'who', 'what_title', 'what_frequencies',\n",
      "       'what_language', 'what_weblink', 'what_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(fx.columns)\n",
    "print(speeches.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfde02-f2d1-4f91-bf7c-873e1ad4d3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
